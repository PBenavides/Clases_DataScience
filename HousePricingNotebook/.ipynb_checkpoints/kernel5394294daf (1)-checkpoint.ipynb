{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing data\n",
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()\n",
    "print('------------------------------------------------------------')\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breve descripción numérica de los datos: \n",
    "En el train data tenemos 1460 datos con 81 columnas, mientras que el test data tenemos 1459 datos con 80 columnas (se entiende que es la data sobre la que tendremos que hacer nuestras predicciones)\n",
    "\n",
    "-Por eso, posteriormente a transformar los datos de train y test, tenemos que partir el train data en otros dos subsets y evaluarlo con eso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            Pasaremos a ver cuáles son las columnas que tienen valores nulos. Tanto en test como en train.\n",
    "            Aparte, meteremos la cantidad total de valores nulos dentro de un diccionario con su respectiva columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo diccionarios\n",
    "null_dict_train = {}\n",
    "null_dict_test = {}\n",
    "for i in df_train.columns:\n",
    "    if df_train[i].isna().any() == True:\n",
    "        print('La columna', i, 'tiene', df_train[i].isna().sum(), 'valores nulos <--------')\n",
    "        null_dict_train[i] = df_train[i].isna().sum() #Creo los key and values de los diccionarios\n",
    "    else:\n",
    "        pass\n",
    "print('-------------------------------------------------------Ahora para test-------------------------------------------------')\n",
    "\n",
    "for i in df_test.columns:\n",
    "    if df_test[i].isna().any() == True:\n",
    "        print('La columna', i, 'tiene', df_test[i].isna().sum(), 'valores nulos <--------')\n",
    "        null_dict_test[i] = df_test[i].isna().sum()  #Creo los key and values de los diccionarios\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Según la teoría si el 30% de la data es nula se debería eliminar, qué columnas cumplen con esto?\n",
    "\n",
    "Teniendo en cuenta que nuesto df_train tiene 1460 valores y nuestro df_test tiene 1459 valores. Aplicaremos una función que nos saque el porcentaje para cada valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Haremos dict comprehension\n",
    "#para cada key voy a sacarle el porcentaje de valores nulos con respecto a la data total\n",
    "null_dict_train_percentage = {k: (v/1460)*100 for k, v in null_dict_train.items()} \n",
    "null_dict_test_percentage = {k: (v/1459)*100 for k, v in null_dict_test.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(null_dict_train_percentage)\n",
    "print('-------------------------------------------------------------------------------------')\n",
    "print(null_dict_test_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En una vista rápida diremos que:\n",
    " ##### Para el train dataframe:\n",
    "- Las columnas 'Alley', 'FireplaceQu', 'PoolQC', 'Fence' y 'MiscFeature' tienen más del 30% de la data nula\n",
    "\n",
    " ##### Para el test dataframe:\n",
    "- Las columnas 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature' tienen más del 30% de la data nula.\n",
    "\n",
    "Entonces también concluimos que tanto los dataframe de test y train tienen la misma recurrencia en data nula por las mismas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_corr = df_train.corr()\n",
    "plt.figure(figsize=(12,9))\n",
    "sns.heatmap(data_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "cols = data_corr.nlargest(k,'SalePrice')['SalePrice'].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
