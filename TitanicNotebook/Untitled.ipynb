{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "-Logistic regression vs SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaremos de esta manera los archivos csv donde encontraremos la data que nos interesa. Se puede observar que tenemos dos conjuntos de datos: **train** y **test**. Esto es porque el **objetivo** es hacer un modelo de aprendizaje automático (machine learning), específicamente uno supervizado que nos prediga si el pasajero **sobrevive** o **no sobrevive**. Se divide la data porque cierto grupo de datos nos servirá para **entrenar** el modelo y el otro grupo de datos para **testearlo**. Luego de hacer el respectivo testeo del modelo podremos mandarlo a producción, es decir, que interactúe con data real.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = train.loc[:,'Pclass':]\n",
    "y_train = train.loc[:,'Survived']\n",
    "X_test_final = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression  (81.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Dividing the data before tuning the model\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_train,y_train,test_size = 0.3, \n",
    "                                                    random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 106, 111, 116, 121, 126, 131, 136, 141, 146, 151, 156, 161, 166, 171, 176, 181, 186, 191, 196, 201, 206, 211, 216, 221, 226, 231, 236, 241, 246, 251, 256, 261, 266, 271, 276, 281, 286, 291, 296, 301,...16, 4921, 4926, 4931, 4936, 4941, 4946, 4951, 4956, 4961, 4966, 4971, 4976, 4981, 4986, 4991, 4996]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression:\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "param_grid = {'C' : [x for x in range(1,5000,5)]  }\n",
    "\n",
    "#finding the best parameter:\n",
    "searcher = GridSearchCV(logreg, param_grid)\n",
    "\n",
    "searcher.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV params {'C': 4581}\n",
      "Best CV accuracy 0.8057784911717496\n",
      "Test accuracy of best grid search hypers: 0.8171641791044776\n"
     ]
    }
   ],
   "source": [
    "# Report the best parameters and the corresponding score\n",
    "print(\"Best CV params\", searcher.best_params_)\n",
    "print(\"Best CV accuracy\", searcher.best_score_)\n",
    "\n",
    "# Report the summitaccuracy using these best parameters\n",
    "print(\"summitaccuracy of best grid search hypers:\", searcher.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = searcher.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines: \n",
    "#### Support Vector Classifier (81,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'gamma': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100], 'C': [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6, 0.7000000000000001, 0.8, 0.9, 1.0, 1.1, 1.2000000000000002, 1.3000000000000003, 1.4000000000000001, 1.5000000000000002, 1.6, 1.7000000000000002, 1.8000000000000003, 1.9000000000000...8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9.0, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.700000000000001, 9.8, 9.9, 10.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "parameters = {'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1,1,10,100],\n",
    "              'C':[x for x in np.linspace(0.1,10,100)]}\n",
    "ssp = GridSearchCV(svc,parameters)\n",
    "\n",
    "ssp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV params {'C': 1.1, 'gamma': 0.1}\n",
      "Best CV accuracy 0.8186195826645265\n",
      "Test accuracy of best grid search hypers: 0.8171641791044776\n"
     ]
    }
   ],
   "source": [
    "# Report the best parameters and the corresponding score\n",
    "print(\"Best CV params\", ssp.best_params_)\n",
    "print(\"Best CV accuracy\", ssp.best_score_)\n",
    "\n",
    "# Report the summitaccuracy using these best parameters\n",
    "print(\"summitaccuracy of best grid search hypers:\", searcher.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred23 = ssp.predict(X_test)\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_kg_hide-output": true,
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617    0\n",
       "379    0\n",
       "725    0\n",
       "826    0\n",
       "450    0\n",
       "147    0\n",
       "698    0\n",
       "397    0\n",
       "525    0\n",
       "505    0\n",
       "180    0\n",
       "255    1\n",
       "433    0\n",
       "232    0\n",
       "405    0\n",
       "131    0\n",
       "723    0\n",
       "16     0\n",
       "516    1\n",
       "128    1\n",
       "119    0\n",
       "383    1\n",
       "536    0\n",
       "126    0\n",
       "44     1\n",
       "618    1\n",
       "65     1\n",
       "627    1\n",
       "567    0\n",
       "426    1\n",
       "      ..\n",
       "750    1\n",
       "375    1\n",
       "148    0\n",
       "381    1\n",
       "823    1\n",
       "439    0\n",
       "52     1\n",
       "290    1\n",
       "713    0\n",
       "597    0\n",
       "351    0\n",
       "822    0\n",
       "398    0\n",
       "173    0\n",
       "142    1\n",
       "200    0\n",
       "441    0\n",
       "68     1\n",
       "170    0\n",
       "272    1\n",
       "648    0\n",
       "805    0\n",
       "178    0\n",
       "714    0\n",
       "520    1\n",
       "394    1\n",
       "463    0\n",
       "13     0\n",
       "12     0\n",
       "649    1\n",
       "Name: Survived, Length: 268, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent Classifier (81,7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV params {'C': 4581}\n",
      "Best CV accuracy 0.8057784911717496\n",
      "Test accuracy of best grid search hypers: 0.8171641791044776\n"
     ]
    }
   ],
   "source": [
    "# We set random_state=0 for reproducibility \n",
    "linear_classifier = SGDClassifier(random_state=0)\n",
    "\n",
    "# Instantiate the GridSearchCV object and run the search\n",
    "parameters = {'alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1], \n",
    "             'loss':['hinge', 'log'], 'penalty':['l1','l2']}\n",
    "searcher_sgd = GridSearchCV(linear_classifier, parameters, cv=10)\n",
    "searcher_sgd.fit(X_train, y_train)\n",
    "\n",
    "# Report the best parameters and the corresponding score\n",
    "print(\"Best CV params\", searcher.best_params_)\n",
    "print(\"Best CV accuracy\", searcher.best_score_)\n",
    "print(\"summitaccuracy of best grid search hypers:\", searcher.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees Classifier (0.79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz #importing the module\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the Decision Trees model: 0.7873134328358209 for max_depth:  1\n",
      "Test accuracy of the Decision Trees model: 0.8022388059701493 for max_depth:  2\n",
      "Test accuracy of the Decision Trees model: 0.832089552238806 for max_depth:  3\n",
      "Test accuracy of the Decision Trees model: 0.835820895522388 for max_depth:  4\n",
      "Test accuracy of the Decision Trees model: 0.8097014925373134 for max_depth:  5\n",
      "Test accuracy of the Decision Trees model: 0.7985074626865671 for max_depth:  6\n",
      "Test accuracy of the Decision Trees model: 0.8208955223880597 for max_depth:  7\n",
      "Test accuracy of the Decision Trees model: 0.8171641791044776 for max_depth:  8\n",
      "Test accuracy of the Decision Trees model: 0.8134328358208955 for max_depth:  9\n",
      "Test accuracy of the Decision Trees model: 0.8171641791044776 for max_depth:  10\n",
      "Test accuracy of the Decision Trees model: 0.7985074626865671 for max_depth:  11\n",
      "Test accuracy of the Decision Trees model: 0.7798507462686567 for max_depth:  12\n",
      "Test accuracy of the Decision Trees model: 0.7835820895522388 for max_depth:  13\n",
      "Test accuracy of the Decision Trees model: 0.7798507462686567 for max_depth:  14\n",
      "Test accuracy of the Decision Trees model: 0.7798507462686567 for max_depth:  15\n",
      "Test accuracy of the Decision Trees model: 0.7723880597014925 for max_depth:  16\n",
      "Test accuracy of the Decision Trees model: 0.7649253731343284 for max_depth:  17\n"
     ]
    }
   ],
   "source": [
    "#Finding our optimize max_depth\n",
    "for i in range(1,18):\n",
    "    tree_clf = DecisionTreeClassifier(max_depth=i)\n",
    "    tree_clf.fit(X_train,y_train)\n",
    "    y_pred = tree_clf.predict(X_test)\n",
    "    print(\"summitaccuracy of the Decision Trees model:\", accuracy_score(y_pred,y_test), \"for max_depth: \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the Decision Trees model: 0.8022388059701493\n"
     ]
    }
   ],
   "source": [
    "#Basic Decision Tree model\n",
    "tree_clf = DecisionTreeClassifier(max_depth = 2)\n",
    "tree_clf.fit(X_train,y_train) #training the model\n",
    "\n",
    "#Predicting with the model\n",
    "y_pred = tree_clf.predict(X_test)\n",
    "\n",
    "#We will try to evaluate the accuracy score\n",
    "print(\"summitaccuracy of the Decision Trees model:\", accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tree_clf.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST MODEL  (0.81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the Decision Trees model: 0.8283582089552238\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier model\n",
    "rnd_clf = RandomForestClassifier(n_estimators = 500, max_leaf_nodes = 16, n_jobs = -1)\n",
    "rnd_clf.fit(X_train,y_train)\n",
    "\n",
    "#Predicting\n",
    "y_pred = rnd_clf.predict(X_test)\n",
    "\n",
    "#Evaluate the accuracy score\n",
    "print(\"summitaccuracy of the Decision Trees model:\", accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rnd_clf.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Method (all the models) [0.805]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='w...      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'))],\n",
       "         flatten_transform=None, n_jobs=None, voting='hard', weights=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will now try an ensemble method\n",
    "voting_clf = VotingClassifier(estimators = [('lr',searcher),('rf',rnd_clf),('svc',ssp),\n",
    "                                            ('sgd',searcher_sgd),('dt',tree_clf)],\n",
    "                             voting = 'hard')\n",
    "voting_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the Decision Trees model: 0.8208955223880597\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the accuracy score\n",
    "print(\"summitaccuracy of the Decision Trees model:\", accuracy_score(y_pred,y_test))\n",
    "pred = voting_clf.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adb_clf = AdaBoostClassifier(base_estimator = tree_clf,\n",
    "                             n_estimators = 100)\n",
    "adb_clf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_kg_hide-output": true,
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = adb_clf.predict(X_test_final)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "n_cols = X_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation='relu',input_shape = (n_cols,)))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(optimizer='sgd', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_kg_hide-output": true,
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 0.6882 - acc: 0.5939\n",
      "Epoch 2/100\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.5930 - acc: 0.7352\n",
      "Epoch 3/100\n",
      "623/623 [==============================] - 0s 48us/step - loss: 0.5575 - acc: 0.7608\n",
      "Epoch 4/100\n",
      "623/623 [==============================] - 0s 54us/step - loss: 0.5314 - acc: 0.7785\n",
      "Epoch 5/100\n",
      "623/623 [==============================] - 0s 55us/step - loss: 0.5129 - acc: 0.7801\n",
      "Epoch 6/100\n",
      "623/623 [==============================] - 0s 56us/step - loss: 0.4997 - acc: 0.7833\n",
      "Epoch 7/100\n",
      "623/623 [==============================] - 0s 56us/step - loss: 0.4896 - acc: 0.7833\n",
      "Epoch 8/100\n",
      "623/623 [==============================] - 0s 50us/step - loss: 0.4814 - acc: 0.7897\n",
      "Epoch 9/100\n",
      "623/623 [==============================] - 0s 52us/step - loss: 0.4757 - acc: 0.7865\n",
      "Epoch 10/100\n",
      "623/623 [==============================] - 0s 56us/step - loss: 0.4731 - acc: 0.7849\n",
      "Epoch 11/100\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.4684 - acc: 0.7849\n",
      "Epoch 12/100\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.4658 - acc: 0.7913\n",
      "Epoch 13/100\n",
      "623/623 [==============================] - 0s 48us/step - loss: 0.4663 - acc: 0.7833\n",
      "Epoch 14/100\n",
      "623/623 [==============================] - 0s 55us/step - loss: 0.4628 - acc: 0.7849\n",
      "Epoch 15/100\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.4619 - acc: 0.7978\n",
      "Epoch 16/100\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.4604 - acc: 0.7929\n",
      "Epoch 17/100\n",
      "623/623 [==============================] - 0s 51us/step - loss: 0.4604 - acc: 0.7897\n",
      "Epoch 18/100\n",
      "623/623 [==============================] - 0s 46us/step - loss: 0.4601 - acc: 0.7961\n",
      "Epoch 19/100\n",
      "623/623 [==============================] - 0s 47us/step - loss: 0.4576 - acc: 0.7961\n",
      "Epoch 20/100\n",
      "623/623 [==============================] - 0s 49us/step - loss: 0.4592 - acc: 0.7881\n",
      "Epoch 21/100\n",
      "623/623 [==============================] - 0s 53us/step - loss: 0.4578 - acc: 0.7913\n",
      "Epoch 22/100\n",
      "623/623 [==============================] - 0s 48us/step - loss: 0.4563 - acc: 0.7913\n",
      "Epoch 23/100\n",
      "623/623 [==============================] - 0s 48us/step - loss: 0.4561 - acc: 0.7865\n",
      "Epoch 24/100\n",
      "623/623 [==============================] - 0s 43us/step - loss: 0.4552 - acc: 0.7978\n",
      "Epoch 25/100\n",
      "623/623 [==============================] - 0s 47us/step - loss: 0.4563 - acc: 0.7897\n",
      "Epoch 26/100\n",
      "623/623 [==============================] - 0s 46us/step - loss: 0.4559 - acc: 0.7929\n",
      "Epoch 27/100\n",
      "623/623 [==============================] - 0s 52us/step - loss: 0.4541 - acc: 0.7961\n",
      "Epoch 28/100\n",
      "623/623 [==============================] - 0s 50us/step - loss: 0.4553 - acc: 0.7929\n",
      "Epoch 29/100\n",
      "623/623 [==============================] - 0s 55us/step - loss: 0.4544 - acc: 0.7945\n",
      "Epoch 30/100\n",
      "623/623 [==============================] - 0s 55us/step - loss: 0.4541 - acc: 0.7945\n",
      "Epoch 31/100\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.4519 - acc: 0.7913\n",
      "Epoch 32/100\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.4541 - acc: 0.7897\n",
      "Epoch 33/100\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.4525 - acc: 0.7994\n",
      "Epoch 34/100\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.4534 - acc: 0.7978\n",
      "Epoch 35/100\n",
      "623/623 [==============================] - 0s 54us/step - loss: 0.4524 - acc: 0.7978\n",
      "Epoch 36/100\n",
      "623/623 [==============================] - 0s 53us/step - loss: 0.4520 - acc: 0.7978\n",
      "Epoch 37/100\n",
      "623/623 [==============================] - 0s 48us/step - loss: 0.4525 - acc: 0.7978\n",
      "Epoch 38/100\n",
      "623/623 [==============================] - 0s 48us/step - loss: 0.4514 - acc: 0.7945\n",
      "Epoch 39/100\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.4506 - acc: 0.7978\n",
      "Epoch 40/100\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.4506 - acc: 0.8042\n",
      "Epoch 41/100\n",
      "623/623 [==============================] - 0s 54us/step - loss: 0.4499 - acc: 0.8010\n",
      "Epoch 42/100\n",
      "623/623 [==============================] - 0s 55us/step - loss: 0.4498 - acc: 0.7978\n",
      "Epoch 43/100\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.4498 - acc: 0.8026\n",
      "Epoch 44/100\n",
      "623/623 [==============================] - 0s 50us/step - loss: 0.4493 - acc: 0.8010\n",
      "Epoch 45/100\n",
      "623/623 [==============================] - 0s 48us/step - loss: 0.4480 - acc: 0.7978\n",
      "Epoch 46/100\n",
      "623/623 [==============================] - 0s 45us/step - loss: 0.4491 - acc: 0.7978\n",
      "Epoch 47/100\n",
      "623/623 [==============================] - 0s 44us/step - loss: 0.4474 - acc: 0.8026\n",
      "Epoch 48/100\n",
      "623/623 [==============================] - 0s 43us/step - loss: 0.4504 - acc: 0.7961\n",
      "Epoch 49/100\n",
      "623/623 [==============================] - 0s 43us/step - loss: 0.4483 - acc: 0.7978\n",
      "Epoch 50/100\n",
      "623/623 [==============================] - 0s 44us/step - loss: 0.4471 - acc: 0.8010\n",
      "Epoch 51/100\n",
      "623/623 [==============================] - 0s 42us/step - loss: 0.4482 - acc: 0.7929\n",
      "Epoch 52/100\n",
      "623/623 [==============================] - 0s 42us/step - loss: 0.4482 - acc: 0.7961\n",
      "Epoch 53/100\n",
      "623/623 [==============================] - 0s 42us/step - loss: 0.4486 - acc: 0.8026\n",
      "Epoch 54/100\n",
      "623/623 [==============================] - 0s 43us/step - loss: 0.4473 - acc: 0.7994\n",
      "Epoch 55/100\n",
      "623/623 [==============================] - 0s 48us/step - loss: 0.4474 - acc: 0.8042\n",
      "Epoch 56/100\n",
      "623/623 [==============================] - 0s 47us/step - loss: 0.4467 - acc: 0.7978\n",
      "Epoch 57/100\n",
      "623/623 [==============================] - 0s 45us/step - loss: 0.4463 - acc: 0.8042\n",
      "Epoch 58/100\n",
      "623/623 [==============================] - 0s 44us/step - loss: 0.4463 - acc: 0.8010\n",
      "Epoch 59/100\n",
      "623/623 [==============================] - 0s 47us/step - loss: 0.4451 - acc: 0.8138\n",
      "Epoch 60/100\n",
      "623/623 [==============================] - 0s 44us/step - loss: 0.4463 - acc: 0.8010\n",
      "Epoch 61/100\n",
      "623/623 [==============================] - 0s 44us/step - loss: 0.4455 - acc: 0.7961\n",
      "Epoch 62/100\n",
      "623/623 [==============================] - 0s 52us/step - loss: 0.4444 - acc: 0.8106\n",
      "Epoch 63/100\n",
      "623/623 [==============================] - 0s 52us/step - loss: 0.4446 - acc: 0.8010\n",
      "Epoch 64/100\n",
      "623/623 [==============================] - 0s 50us/step - loss: 0.4451 - acc: 0.7994\n",
      "Epoch 65/100\n",
      "623/623 [==============================] - 0s 42us/step - loss: 0.4442 - acc: 0.7961\n",
      "Epoch 66/100\n",
      "623/623 [==============================] - 0s 43us/step - loss: 0.4450 - acc: 0.8042\n",
      "Epoch 67/100\n",
      "623/623 [==============================] - 0s 42us/step - loss: 0.4453 - acc: 0.8026\n",
      "Epoch 68/100\n",
      "623/623 [==============================] - 0s 40us/step - loss: 0.4438 - acc: 0.8042\n",
      "Epoch 69/100\n",
      "623/623 [==============================] - 0s 46us/step - loss: 0.4452 - acc: 0.7994\n",
      "Epoch 70/100\n",
      "623/623 [==============================] - 0s 40us/step - loss: 0.4436 - acc: 0.7978\n",
      "Epoch 71/100\n",
      "623/623 [==============================] - 0s 39us/step - loss: 0.4436 - acc: 0.8058\n",
      "Epoch 72/100\n",
      "623/623 [==============================] - 0s 43us/step - loss: 0.4426 - acc: 0.7978\n",
      "Epoch 73/100\n",
      "623/623 [==============================] - 0s 48us/step - loss: 0.4422 - acc: 0.8042\n",
      "Epoch 74/100\n",
      "623/623 [==============================] - 0s 42us/step - loss: 0.4417 - acc: 0.8042\n",
      "Epoch 75/100\n",
      "623/623 [==============================] - 0s 42us/step - loss: 0.4436 - acc: 0.8042\n",
      "Epoch 76/100\n",
      "623/623 [==============================] - 0s 42us/step - loss: 0.4426 - acc: 0.8042\n",
      "Epoch 77/100\n",
      "623/623 [==============================] - 0s 41us/step - loss: 0.4425 - acc: 0.8074\n",
      "Epoch 78/100\n",
      "623/623 [==============================] - 0s 41us/step - loss: 0.4407 - acc: 0.8090\n",
      "Epoch 79/100\n",
      "623/623 [==============================] - 0s 44us/step - loss: 0.4416 - acc: 0.8026\n",
      "Epoch 80/100\n",
      "623/623 [==============================] - 0s 43us/step - loss: 0.4402 - acc: 0.8026\n",
      "Epoch 81/100\n",
      "623/623 [==============================] - 0s 43us/step - loss: 0.4426 - acc: 0.8074\n",
      "Epoch 82/100\n",
      "623/623 [==============================] - 0s 46us/step - loss: 0.4413 - acc: 0.8106\n",
      "Epoch 83/100\n",
      "623/623 [==============================] - 0s 40us/step - loss: 0.4409 - acc: 0.8058\n",
      "Epoch 84/100\n",
      "623/623 [==============================] - 0s 43us/step - loss: 0.4421 - acc: 0.8058\n",
      "Epoch 85/100\n",
      "623/623 [==============================] - 0s 42us/step - loss: 0.4407 - acc: 0.8074\n",
      "Epoch 86/100\n",
      "623/623 [==============================] - 0s 40us/step - loss: 0.4418 - acc: 0.8074\n",
      "Epoch 87/100\n",
      "623/623 [==============================] - 0s 40us/step - loss: 0.4392 - acc: 0.8090\n",
      "Epoch 88/100\n",
      "623/623 [==============================] - 0s 41us/step - loss: 0.4403 - acc: 0.8058\n",
      "Epoch 89/100\n",
      "623/623 [==============================] - 0s 44us/step - loss: 0.4414 - acc: 0.8106\n",
      "Epoch 90/100\n",
      "623/623 [==============================] - 0s 42us/step - loss: 0.4398 - acc: 0.8042\n",
      "Epoch 91/100\n",
      "623/623 [==============================] - 0s 51us/step - loss: 0.4399 - acc: 0.8074\n",
      "Epoch 92/100\n",
      "623/623 [==============================] - 0s 52us/step - loss: 0.4388 - acc: 0.8106\n",
      "Epoch 93/100\n",
      "623/623 [==============================] - 0s 42us/step - loss: 0.4400 - acc: 0.8074\n",
      "Epoch 94/100\n",
      "623/623 [==============================] - 0s 43us/step - loss: 0.4394 - acc: 0.8042\n",
      "Epoch 95/100\n",
      "623/623 [==============================] - 0s 50us/step - loss: 0.4404 - acc: 0.8058\n",
      "Epoch 96/100\n",
      "623/623 [==============================] - 0s 44us/step - loss: 0.4384 - acc: 0.8074\n",
      "Epoch 97/100\n",
      "623/623 [==============================] - 0s 41us/step - loss: 0.4390 - acc: 0.8074\n",
      "Epoch 98/100\n",
      "623/623 [==============================] - 0s 41us/step - loss: 0.4407 - acc: 0.8058\n",
      "Epoch 99/100\n",
      "623/623 [==============================] - 0s 41us/step - loss: 0.4395 - acc: 0.8122\n",
      "Epoch 100/100\n",
      "623/623 [==============================] - 0s 42us/step - loss: 0.4368 - acc: 0.8138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4861790e80>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train2, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}